2024-03-30 11:03:58,237 - INFO - 
#########
BYOL Training!!!
#########
2024-03-30 11:03:58,238 - INFO - Args parsed succesfully
2024-03-30 11:03:58,238 - INFO - Params: Namespace(epochs=30, exp_name='BYOL_No_Normalization', fine_tune=True, net_name='resnet18')
2024-03-30 11:03:58,597 - INFO - Model for BYOL was initialized and sent to cuda:0
2024-03-30 11:03:58,598 - INFO - BYOL(
  (backbone): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (8): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (projection_head): BYOLProjectionHead(
    (layers): Sequential(
      (0): Linear(in_features=512, out_features=1024, bias=False)
      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
    )
  )
  (prediction_head): BYOLPredictionHead(
    (layers): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=False)
      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
    )
  )
  (backbone_momentum): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (8): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (projection_head_momentum): BYOLProjectionHead(
    (layers): Sequential(
      (0): Linear(in_features=512, out_features=1024, bias=False)
      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=1024, out_features=256, bias=True)
    )
  )
)
2024-03-30 11:03:59,474 - INFO - All data has been loaded
2024-03-30 11:03:59,475 - INFO - Got hyper parametrs for current model:
2024-03-30 11:03:59,475 - INFO - batch size=32
2024-03-30 11:03:59,475 - INFO - Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 2e-05
)
2024-03-30 11:03:59,475 - INFO - DataLoader initialized
2024-03-30 11:03:59,475 - INFO - HyperParams initiliazed, starting training...
2024-03-30 11:05:49,584 - INFO - Epoch: 0 | Loss: -790.6260 | Epoch Time: 110.11 secs
2024-03-30 11:07:39,294 - INFO - Epoch: 1 | Loss: -859.1061 | Epoch Time: 109.70 secs
2024-03-30 11:09:30,155 - INFO - Epoch: 2 | Loss: -862.1362 | Epoch Time: 110.85 secs
2024-03-30 11:11:21,843 - INFO - Epoch: 3 | Loss: -864.3842 | Epoch Time: 111.68 secs
2024-03-30 11:13:12,823 - INFO - Epoch: 4 | Loss: -865.9401 | Epoch Time: 110.97 secs
2024-03-30 11:15:03,152 - INFO - Epoch: 5 | Loss: -867.6893 | Epoch Time: 110.32 secs
2024-03-30 11:16:53,366 - INFO - Epoch: 6 | Loss: -870.0032 | Epoch Time: 110.21 secs
2024-03-30 11:18:43,090 - INFO - Epoch: 7 | Loss: -872.0752 | Epoch Time: 109.72 secs
2024-03-30 11:20:33,402 - INFO - Epoch: 8 | Loss: -874.2416 | Epoch Time: 110.30 secs
2024-03-30 11:22:23,353 - INFO - Epoch: 9 | Loss: -876.2753 | Epoch Time: 109.94 secs
2024-03-30 11:24:13,430 - INFO - Epoch: 10 | Loss: -878.3359 | Epoch Time: 110.07 secs
2024-03-30 11:26:03,805 - INFO - Epoch: 11 | Loss: -880.1480 | Epoch Time: 110.37 secs
2024-03-30 11:27:54,454 - INFO - Epoch: 12 | Loss: -881.5997 | Epoch Time: 110.64 secs
2024-03-30 11:29:45,228 - INFO - Epoch: 13 | Loss: -882.7623 | Epoch Time: 110.77 secs
2024-03-30 11:31:35,683 - INFO - Epoch: 14 | Loss: -883.4418 | Epoch Time: 110.45 secs
2024-03-30 11:33:26,648 - INFO - Epoch: 15 | Loss: -884.1498 | Epoch Time: 110.96 secs
2024-03-30 11:35:17,954 - INFO - Epoch: 16 | Loss: -884.6336 | Epoch Time: 111.30 secs
2024-03-30 11:37:10,382 - INFO - Epoch: 17 | Loss: -884.7979 | Epoch Time: 112.42 secs
2024-03-30 11:39:02,244 - INFO - Epoch: 18 | Loss: -885.1499 | Epoch Time: 111.85 secs
2024-03-30 11:40:53,391 - INFO - Epoch: 19 | Loss: -885.3513 | Epoch Time: 111.14 secs
2024-03-30 11:42:43,512 - INFO - Epoch: 20 | Loss: -885.4850 | Epoch Time: 110.11 secs
2024-03-30 11:44:34,354 - INFO - Epoch: 21 | Loss: -885.5341 | Epoch Time: 110.83 secs
2024-03-30 11:46:25,833 - INFO - Epoch: 22 | Loss: -885.9277 | Epoch Time: 111.47 secs
2024-03-30 11:48:16,590 - INFO - Epoch: 23 | Loss: -885.8269 | Epoch Time: 110.75 secs
2024-03-30 11:50:06,738 - INFO - Epoch: 24 | Loss: -885.9969 | Epoch Time: 110.14 secs
2024-03-30 11:51:57,404 - INFO - Epoch: 25 | Loss: -886.1875 | Epoch Time: 110.66 secs
2024-03-30 11:53:47,817 - INFO - Epoch: 26 | Loss: -886.0540 | Epoch Time: 110.41 secs
2024-03-30 11:55:38,353 - INFO - Epoch: 27 | Loss: -886.1724 | Epoch Time: 110.53 secs
2024-03-30 11:57:29,333 - INFO - Epoch: 28 | Loss: -886.2107 | Epoch Time: 110.97 secs
2024-03-30 11:59:20,230 - INFO - Epoch: 29 | Loss: -886.3553 | Epoch Time: 110.89 secs
2024-03-30 11:59:20,445 - INFO - Train BYOL Ended!
